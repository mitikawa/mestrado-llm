\section{Limitações}
\label{sec:limitacoes}

Apesar das contribuições apresentadas na análise da interseção entre subjetividade e autoria, este estudo opera sob restrições metodológicas e de dados que delimitam o escopo de suas conclusões.

\paragraph{Restrições do Dataset de Subjetividade:} A limitação mais crítica reside na dimensão e especificidade do corpus NewsSD-ENG. Com apenas 731 sentenças de treino e um desbalanceamento de classes de 2:1, a capacidade de generalização dos modelos $M_{SD}$ é restrita. Ademais, o NewsSD-ENG é focado estritamente no domínio jornalístico. Em contraste, o dataset de MGTD (SemEval-2024) é multi-domínio, abrangendo desde escrita criativa até técnica. Existe, portanto, um risco de \textit{domain shift}, onde o modelo de subjetividade pode interpretar incorretamente características estilísticas de outros domínios (como ficção) como sendo subjetividade jornalística.

\paragraph{Forma de Agregação:} A estratégia de calcular o Índice de Subjetividade ($I_{subj}$) através da média aritmética das probabilidades das sentenças  constitui uma simplificação. Esta abordagem ignora a estrutura discursiva e a interdependência sequencial do texto. Um documento pode ser globalmente objetivo, mas conter uma única sentença altamente subjetiva que altera sua percepção semântica, nuance esta que pode focar diluída em uma média simples.

\paragraph{Propagação de Erro:} A metodologia adota uma abordagem em cascata (\textit{pipeline}), onde a análise das Questões de Pesquisa (Q1 e Q2) depende inteiramente da precisão do classificador $M_{SD}$. Erros de classificação no primeiro estágio (falsos positivos de subjetividade) propagam-se para a análise subsequente, podendo introduzir ruído nas correlações observadas entre subjetividade e detecção de autoria.

\paragraph{Escopo Arquitetural:} Finalmente, focamos em modelos baseados em arquiteturas \textit{encoder-only} da família BERT (DistilBERT, BERT e RoBERTa). Embora eficientes, estes modelos possuem uma janela de contexto e capacidade de raciocínio inferiores aos \textit{Large Language Models} (LLMs) generativos atuais (e.g., GPT-4, Llama-3). É possível que modelos maiores capturem nuances de subjetividade pragmática que escapam às arquiteturas avaliadas neste estudo, porém questões limitantes de recursos definiram as escolhas.

\paragraph{Otimização de Hiperparâmetros:} Devido a restrições temporais, não foi possível realizar uma busca de hiperparâmetros (como \textit{Grid Search}). Adotamos valores padrões onde possível para parâmetros críticos como \textit{learning rate}, \textit{batch size} e configurações do LoRA (rank e alpha). É provavel que o desempenho dos modelos poderia ser superior com um ajuste fino mais rigoroso.