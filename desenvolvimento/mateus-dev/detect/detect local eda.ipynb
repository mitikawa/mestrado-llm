{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 8475,
     "status": "ok",
     "timestamp": 1761853187068,
     "user": {
      "displayName": "Mateus Abreu Itikawa",
      "userId": "07527184323391034917"
     },
     "user_tz": 180
    },
    "id": "bbe99089",
    "outputId": "56221397-24a8-4c9b-b38a-d69c576d75df",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>model</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forza Motorsport is a popular racing game that...</td>\n",
       "      <td>1</td>\n",
       "      <td>chatGPT</td>\n",
       "      <td>wikihow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buying Virtual Console games for your Nintendo...</td>\n",
       "      <td>1</td>\n",
       "      <td>chatGPT</td>\n",
       "      <td>wikihow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Windows NT 4.0 was a popular operating system ...</td>\n",
       "      <td>1</td>\n",
       "      <td>chatGPT</td>\n",
       "      <td>wikihow</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to Make Perfume\\n\\nPerfume is a great way ...</td>\n",
       "      <td>1</td>\n",
       "      <td>chatGPT</td>\n",
       "      <td>wikihow</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to Convert Song Lyrics to a Song'\\n\\nConve...</td>\n",
       "      <td>1</td>\n",
       "      <td>chatGPT</td>\n",
       "      <td>wikihow</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label    model   source  \\\n",
       "0  Forza Motorsport is a popular racing game that...      1  chatGPT  wikihow   \n",
       "1  Buying Virtual Console games for your Nintendo...      1  chatGPT  wikihow   \n",
       "2  Windows NT 4.0 was a popular operating system ...      1  chatGPT  wikihow   \n",
       "3  How to Make Perfume\\n\\nPerfume is a great way ...      1  chatGPT  wikihow   \n",
       "4  How to Convert Song Lyrics to a Song'\\n\\nConve...      1  chatGPT  wikihow   \n",
       "\n",
       "   id  \n",
       "0   0  \n",
       "1   1  \n",
       "2   2  \n",
       "3   3  \n",
       "4   4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "ROOT = os.path.abspath(\n",
    "    os.path.join(os.path.dirname(os.path.abspath(\"\")), \"..\", \"..\")\n",
    ")\n",
    "DATA_DIR = os.path.abspath(os.path.join(ROOT, \"dados\"))\n",
    "MODEL_DIR = os.path.abspath(os.path.join(ROOT, \"modelos\"))\n",
    "\n",
    "dev_file_path = os.path.join(DATA_DIR, \"detect\", \"subtaskA_dev_monolingual.jsonl\")\n",
    "train_file_path = os.path.join(DATA_DIR, \"detect\", \"subtaskA_train_monolingual.jsonl\")\n",
    "df_train = pd.read_json(train_file_path, lines=True)\n",
    "df_dev = pd.read_json(dev_file_path, lines=True)\n",
    "\n",
    "df_train = pd.read_json(train_file_path, lines=True)\n",
    "df_train['length'] = df_train['text'].str.len()\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 28060,
     "status": "ok",
     "timestamp": 1761853215344,
     "user": {
      "displayName": "Mateus Abreu Itikawa",
      "userId": "07527184323391034917"
     },
     "user_tz": 180
    },
    "id": "WqCG00scjPBu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74129    This is a list of fictional characters from th...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train[\"length\"]==df_train.length.max()][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2786.013519042728"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_train.length)/119757"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "executionInfo": {
     "elapsed": 2323573,
     "status": "ok",
     "timestamp": 1761855538931,
     "user": {
      "displayName": "Mateus Abreu Itikawa",
      "userId": "07527184323391034917"
     },
     "user_tz": 180
    },
    "id": "cCYX8spmivgZ",
    "outputId": "e4bc9502-506e-4357-b09b-11857e1dafe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution (train):\n",
      "label_str\n",
      "human    63351\n",
      "AI       56406\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution (dev):\n",
      "label_str\n",
      "AI       2500\n",
      "human    2500\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 296,450 || all params: 109,780,228 || trainable%: 0.2700\n",
      "Train dataset size: 119757\n",
      "Dev dataset size: 5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7485' max='7485' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7485/7485 37:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.371200</td>\n",
       "      <td>1.010674</td>\n",
       "      <td>0.636200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.259600</td>\n",
       "      <td>0.964533</td>\n",
       "      <td>0.661600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.245700</td>\n",
       "      <td>0.959750</td>\n",
       "      <td>0.680400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.221200</td>\n",
       "      <td>0.910559</td>\n",
       "      <td>0.688400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.213200</td>\n",
       "      <td>0.845860</td>\n",
       "      <td>0.688000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.205100</td>\n",
       "      <td>0.834596</td>\n",
       "      <td>0.710800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.798629</td>\n",
       "      <td>0.715800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification Report (Human vs. AI) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AI       0.72      0.71      0.71      2500\n",
      "       human       0.71      0.72      0.72      2500\n",
      "\n",
      "    accuracy                           0.72      5000\n",
      "   macro avg       0.72      0.72      0.72      5000\n",
      "weighted avg       0.72      0.72      0.72      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================\n",
    "# 1Ô∏è‚É£ PREPROCESS DATA (Adaptado para Human vs. AI)\n",
    "# ============================================\n",
    "\n",
    "# Fun√ß√£o para criar o r√≥tulo bin√°rio\n",
    "def map_label(model_name):\n",
    "    if model_name == 'human':\n",
    "        return 'human'\n",
    "    else:\n",
    "        return 'AI' # Agrupa 'chatGPT', 'davinci', etc.\n",
    "\n",
    "# Aplica a fun√ß√£o para criar uma nova coluna de r√≥tulo leg√≠vel\n",
    "df_train['label_str'] = df_train['model'].apply(map_label)\n",
    "df_dev['label_str'] = df_dev['model'].apply(map_label)\n",
    "\n",
    "# Mapeia os r√≥tulos de string para inteiros\n",
    "label_map = {\"human\": 0, \"AI\": 1}\n",
    "df_train[\"label_id\"] = df_train[\"label_str\"].map(label_map)\n",
    "df_dev[\"label_id\"] = df_dev[\"label_str\"].map(label_map)\n",
    "\n",
    "print(\"Label distribution (train):\")\n",
    "print(df_train[\"label_str\"].value_counts())\n",
    "print(\"\\nLabel distribution (dev):\")\n",
    "print(df_dev[\"label_str\"].value_counts())\n",
    "\n",
    "# ============================================\n",
    "# 2Ô∏è‚É£ DEFINE DATASET CLASS (Adaptado)\n",
    "# ============================================\n",
    "\n",
    "# class TextDataset(Dataset):\n",
    "#     def __init__(self, df, tokenizer, max_len=128):\n",
    "#         # MUDAN√áA: \"sentence\" -> \"text\"\n",
    "#         self.texts = df[\"text\"].tolist()\n",
    "#         # MUDAN√áA: \"label\" -> \"label_id\" (nossa nova coluna)\n",
    "#         self.labels = df[\"label_id\"].tolist()\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_len = max_len\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.texts)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         text = str(self.texts[idx]) # Adicionado str() para seguran√ßa\n",
    "#         label = self.labels[idx]\n",
    "#         enc = self.tokenizer(\n",
    "#             text,\n",
    "#             truncation=True,\n",
    "#             padding=\"max_length\",\n",
    "#             max_length=self.max_len,\n",
    "#             return_tensors=\"pt\",\n",
    "#         )\n",
    "#         item = {key: val.squeeze() for key, val in enc.items()}\n",
    "#         item[\"labels\"] = torch.tensor(label, dtype=torch.long)\n",
    "#         return item\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128):\n",
    "        self.texts = df[\"text\"].tolist()\n",
    "        self.labels = df[\"label_id\"].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # MUDAN√áA: Removido padding, return_tensors.\n",
    "        # Deixe o DataCollator do Trainer cuidar disso.\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            # N√£o adicione padding aqui!\n",
    "        )\n",
    "\n",
    "        # Retorne um dicion√°rio simples.\n",
    "        # O Trainer cuidar√° de agrupar e converter para tensores.\n",
    "        item = {\n",
    "            \"input_ids\": enc[\"input_ids\"],\n",
    "            \"attention_mask\": enc[\"attention_mask\"],\n",
    "            \"labels\": label\n",
    "        }\n",
    "        return item\n",
    "\n",
    "# ============================================\n",
    "# 3Ô∏è‚É£ LOAD PRETRAINED MODEL + TOKENIZER (Adaptado)\n",
    "# ============================================\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2, # Ainda √© classifica√ß√£o bin√°ria\n",
    "    # MUDAN√áA: Atualiza os r√≥tulos para a nova tarefa\n",
    "    id2label={0: \"human\", 1: \"AI\"},\n",
    "    label2id={\"human\": 0, \"AI\": 1}\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# 4Ô∏è‚É£ ADD LORA ADAPTER (Sem mudan√ßas)\n",
    "# ============================================\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# ============================================\n",
    "# 5Ô∏è‚É£ CREATE DATASETS (Adaptado)\n",
    "# ============================================\n",
    "\n",
    "# Passa os DataFrames corretos\n",
    "train_dataset = TextDataset(df_train, tokenizer)\n",
    "dev_dataset = TextDataset(df_dev, tokenizer)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Dev dataset size: {len(dev_dataset)}\")\n",
    "\n",
    "# ============================================\n",
    "# 6Ô∏è‚É£ DEFINE METRICS (Sem mudan√ßas)\n",
    "# ============================================\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    labels = pred.label_ids\n",
    "    accuracy = (preds == labels).mean()\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "# ============================================\n",
    "# 7Ô∏è‚É£ TRAINING ARGUMENTS (Sem mudan√ßas, mantendo a corre√ß√£o do log)\n",
    "# ============================================\n",
    "# ============================================\n",
    "# 7Ô∏è‚É£ TRAINING ARGUMENTS (Adaptado para dataset GRANDE)\n",
    "# ============================================\n",
    "\n",
    "# Calcule o total de passos de treino (ex: para 1 √©poca com batch 32)\n",
    "# 119757 / 32 = 3742.4 => 3743 passos\n",
    "# Vamos definir nossos logs/evals com base nisso. ex: a cada 1000 passos.\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora_results_human_ai\",\n",
    "    dataloader_num_workers=2,\n",
    "    # --- Mudan√ßas Estrat√©gicas ---\n",
    "    num_train_epochs=1, # 120k amostras √© muito. 1 √©poca √© um √≥timo ponto de partida.\n",
    "\n",
    "    # Aumente o batch size para acelerar o treino (depende da sua VRAM)\n",
    "    per_device_train_batch_size=16,  # Era 16. Tente 128 ou 128.\n",
    "    per_device_eval_batch_size=16,   # Pode ser igual ou maior que o de treino.\n",
    "\n",
    "    # Mude TUDO de \"epoch\" para \"steps\"\n",
    "    eval_strategy=\"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "\n",
    "    # Defina a frequ√™ncia em passos\n",
    "    eval_steps=1000,     # Avalia no dataset de dev a cada 1000 passos\n",
    "    logging_steps=1000,  # Mostra o training loss a cada 1000 passos\n",
    "    save_steps=1000,     # Salva um checkpoint a cada 1000 passos\n",
    "\n",
    "    # --- O resto pode ficar igual ---\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs_human_ai\",\n",
    "    load_best_model_at_end=True, # ESSENCIAL: vai carregar o melhor checkpoint (ex: passo 3000) no final\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# =G==========================================\n",
    "# 8Ô∏è‚É£ TRAINER SETUP (Sem mudan√ßas)\n",
    "# ============================================\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator, # <-- 3. PASSE-O PARA O TRAINER\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# 9Ô∏è‚É£ TRAIN MODEL (Sem mudan√ßas)\n",
    "# ============================================\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# ============================================\n",
    "# üîü EVALUATE MODEL (Adaptado)\n",
    "# ============================================\n",
    "\n",
    "preds_output = trainer.predict(dev_dataset)\n",
    "y_true = preds_output.label_ids\n",
    "y_pred = np.argmax(preds_output.predictions, axis=1)\n",
    "\n",
    "# MUDAN√áA: Atualiza o mapa inverso\n",
    "inv_label_map = {0: \"human\", 1: \"AI\"}\n",
    "y_true_labels = [inv_label_map[i] for i in y_true]\n",
    "y_pred_labels = [inv_label_map[i] for i in y_pred]\n",
    "\n",
    "print(\"\\n--- Classification Report (Human vs. AI) ---\")\n",
    "print(classification_report(y_true_labels, y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 670,
     "status": "ok",
     "timestamp": 1761855773854,
     "user": {
      "displayName": "Mateus Abreu Itikawa",
      "userId": "07527184323391034917"
     },
     "user_tz": 180
    },
    "id": "Nja0yrEVjN9T",
    "outputId": "9785a48e-5cf0-4d4e-f7ea-79a14826e375"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diret√≥rio de salvamento: /content/drive/MyDrive/Mestrado/Modelos de Linguagem/Trabalho LLM/Tarefa Deteccao semeval 2024-8/human_ai_lora_final\n",
      "Salvando adaptadores LoRA em /content/drive/MyDrive/Mestrado/Modelos de Linguagem/Trabalho LLM/Tarefa Deteccao semeval 2024-8/human_ai_lora_final...\n",
      "Modelo e tokenizer salvos permanentemente em seu Google Drive!\n",
      "ls: cannot access '/content/drive/MyDrive/Mestrado/Modelos': No such file or directory\n",
      "ls: cannot access 'de': No such file or directory\n",
      "ls: cannot access 'Linguagem/Trabalho': No such file or directory\n",
      "ls: cannot access 'LLM/Tarefa': No such file or directory\n",
      "ls: cannot access 'Deteccao': No such file or directory\n",
      "ls: cannot access 'semeval': No such file or directory\n",
      "ls: cannot access '2024-8/human_ai_lora_final': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# --- 2. Defina um caminho PERMANENTE ---\n",
    "# Crie um diret√≥rio dentro do seu Drive para este modelo\n",
    "output_dir = \"/content/drive/MyDrive/Mestrado/Modelos de Linguagem/Trabalho LLM/Tarefa Deteccao semeval 2024-8/human_ai_lora_final\"\n",
    "\n",
    "# Crie o diret√≥rio se ele n√£o existir\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Diret√≥rio de salvamento: {output_dir}\")\n",
    "\n",
    "# ============================================\n",
    "# 11. SALVAR O MODELO FINAL\n",
    "# ============================================\n",
    "\n",
    "print(f\"Salvando adaptadores LoRA em {output_dir}...\")\n",
    "\n",
    "# 1. Salve os pesos do adaptador PEFT (LoRA)\n",
    "model.save_pretrained(output_dir)\n",
    "\n",
    "# 2. Salve o tokenizer\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"Modelo e tokenizer salvos permanentemente em seu Google Drive!\")\n",
    "\n",
    "# Verifique os arquivos salvos no seu Drive\n",
    "!ls -lh {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1761855828199,
     "user": {
      "displayName": "Mateus Abreu Itikawa",
      "userId": "07527184323391034917"
     },
     "user_tz": 180
    },
    "id": "3w-B5sYex3bu",
    "outputId": "93c45666-6dd7-48fe-8055-65aefb8f1b56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando o modelo base: bert-base-uncased...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando e aplicando adaptadores LoRA de: /content/drive/MyDrive/Mestrado/Modelos de Linguagem/Trabalho LLM/Tarefa Deteccao semeval 2024-8/human_ai_lora_final...\n",
      "Modelo e tokenizer carregados do Google Drive!\n",
      "Modelo movido para a GPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from google.colab import drive\n",
    "\n",
    "# --- 1. Monte seu Google Drive ---\n",
    "# print(\"Montando Google Drive...\")\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# ============================================\n",
    "# 12. CARREGAR O MODELO SALVO DO DRIVE\n",
    "# ============================================\n",
    "\n",
    "# --- 2. Defina os caminhos ---\n",
    "base_model_name = \"bert-base-uncased\"\n",
    "# O caminho exato onde voc√™ salvou os adaptadores no seu Drive\n",
    "adapter_dir = \"/content/drive/MyDrive/Mestrado/Modelos de Linguagem/Trabalho LLM/Tarefa Deteccao semeval 2024-8/human_ai_lora_final\"\n",
    "\n",
    "print(f\"Carregando o modelo base: {base_model_name}...\")\n",
    "\n",
    "# --- 3. Carregue o Modelo Base ---\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_model_name,\n",
    "    num_labels=2,\n",
    "    id2label={0: \"human\", 1: \"AI\"},\n",
    "    label2id={\"human\": 0, \"AI\": 1}\n",
    ")\n",
    "\n",
    "print(f\"Carregando e aplicando adaptadores LoRA de: {adapter_dir}...\")\n",
    "\n",
    "# --- 4. Aplique os Adaptadores LoRA ---\n",
    "model = PeftModel.from_pretrained(base_model, adapter_dir)\n",
    "\n",
    "# --- 5. Carregue o Tokenizer ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapter_dir)\n",
    "\n",
    "print(\"Modelo e tokenizer carregados do Google Drive!\")\n",
    "\n",
    "# --- 6. Prepare o modelo para infer√™ncia ---\n",
    "model.eval()\n",
    "if torch.cuda.is_available():\n",
    "    model.to(\"cuda\")\n",
    "    print(\"Modelo movido para a GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIr_F1UKx35D"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNzN+nOvwDq1ODz603Vp4F8",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
