{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"2Co5FaIYgcep","outputId":"15efbdb8-e525-4d27-83f7-b8bbda0548bd","executionInfo":{"status":"ok","timestamp":1763662904981,"user_tz":180,"elapsed":14473,"user":{"displayName":"Marcelo Campanelli","userId":"15387875644386929161"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]}],"source":["!pip install transformers datasets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HrlYeHXJiOnR","outputId":"5d968837-8d5c-477d-e413-37c0ac94ae00","executionInfo":{"status":"ok","timestamp":1764444062397,"user_tz":180,"elapsed":7,"user":{"displayName":"Marcelo Nóbrega","userId":"17870542757045971557"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":22}],"source":["# import torch\n","# torch.cuda.is_available()#, torch.cuda.get_device_name(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SHfKacxdg2tO"},"outputs":[],"source":["from datasets import Dataset,load_dataset"]},{"cell_type":"code","source":["#load datasets"],"metadata":{"id":"Z4TPDozcuZYH"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"jPA9lRb2iIAp"},"outputs":[],"source":["ds = load_dataset(\n","    \"csv\",\n","    data_files={\"train\":\"train_en.tsv\",\n","                \"dev\": \"dev_test_en.tsv\",\n","                \"test\": \"test_en_labeled.tsv\"\n","    },\n","    delimiter=\"\\t\"\n",")"]},{"cell_type":"code","source":["def encode_label(example):\n","    example[\"label\"] = 0 if example[\"label\"] == \"OBJ\" else 1\n","    return example\n","#clean ds\n","ds = ds.map(encode_label)\n","ds = ds.rename_column(\"label\", \"labels\")\n","ds = ds.remove_columns(\"sentence_id\")\n","ds = ds.remove_columns(\"solved_conflict\")\n"],"metadata":{"id":"RZSKGWrNXWjt","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U4AMnYYxjbXN"},"outputs":[],"source":["from datasets import ClassLabel\n","import random\n","import pandas as pd\n","from IPython.display import display, HTML\n","\n","def show_random_elements(dataset, num_examples=10):\n","    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n","    picks = []\n","    for _ in range(num_examples):\n","        pick = random.randint(0, len(dataset)-1)\n","        while pick in picks:\n","            pick = random.randint(0, len(dataset)-1)\n","        picks.append(pick)\n","\n","    df = pd.DataFrame(dataset[picks])\n","    for column, typ in dataset.features.items():\n","        if isinstance(typ, ClassLabel):\n","            df[column] = df[column].transform(lambda i: typ.names[i])\n","    display(HTML(df.to_html()))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519},"collapsed":true,"id":"TuMRUnU0jddG","outputId":"9e8a214f-f391-4994-b3c0-05df2906e751","executionInfo":{"status":"ok","timestamp":1763661631349,"user_tz":180,"elapsed":27,"user":{"displayName":"Marcelo Campanelli","userId":"15387875644386929161"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A new variant that can evade vaccines and actually harm people will surface when the ruling class needs another lockdown to panic the unruly slaves into mass compliance out of fear.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>What the Levelling Up Bill is really is a Planning Bill in disguise, something the Committee made clear at the very beginning of their evidence sessions.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>If the natural level of economic recovery were long delayed, then all these measures would very soon fail in the total ruin of public credit.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The tax power, in so many hands, is much less effective than it might be.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A third formation of forces moving in a parallel manner to absorb the national income by extension of government is made up of practical reformers, idealists, good-government people, with or without any political theory.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Therefore, taxes must be increased, first in order to provide as much public revenue as before, and then further increased to provide more revenue than before.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>That the government are shoehorning what is left of their unpopular planning reforms into this Levelling Up legislation speaks to the vacuity of the ‘defining mission’.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>A New England Journal of Medicine study has just confirmed what the data already has: that COVID-19 vaccines are giving people a new form of acquired immunodeficiency syndrome (AIDS).</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Taxes have risen to a point at which they begin to devour people’s possessions, and the taxpayer is wild for relief.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>This makes reading the reports indoctrinated policy wonks write difficult to read because when they write about “immigrants” it is unclear if they actually mean lawfully present immigrants or if they are using the word as a euphemism for illegal aliens.</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}}],"source":["show_random_elements(ds[\"train\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DLRzzIgxYFge"},"outputs":[],"source":["model_checkpoint = 'distilbert/distilbert-base-uncased'\n","tokenizer_checkpoint = 'distilbert/distilbert-base-uncased'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SH6HjbDKYJNO"},"outputs":[],"source":["from transformers import (\n","    AutoTokenizer,\n","    DistilBertTokenizer\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"xZIHzs6matT-"},"outputs":[],"source":["tokenizer = DistilBertTokenizer.from_pretrained(tokenizer_checkpoint,truncation=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XbNbaW8Pay5h"},"outputs":[],"source":["def tokenize_function(examples):\n","    return tokenizer(examples[\"sentence\"],\n","        truncation=True,)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iLTOfd8ovVhI"},"outputs":[],"source":["from transformers import DataCollatorWithPadding\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ww1o9p9qaz5E","collapsed":true},"outputs":[],"source":["# Then tokenize the 'sentence' column and remove it, keeping 'label' and the new tokenized columns.\n","tokenized_datasets = ds.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"sentence\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QFR4xCywTKm8"},"outputs":[],"source":["# caso nao precise agrupar\n","lm_datasets = tokenized_datasets"]},{"cell_type":"markdown","source":["Funcao de perda utilizando Cross-Entropy"],"metadata":{"id":"kMG870DbYdmD"}},{"cell_type":"code","source":["from collections import Counter\n","import torch\n","\n","label_counts = Counter(tokenized_datasets[\"train\"][\"labels\"])\n","num_classes = len(label_counts)\n","\n","# Example: dataset with labels 0 and 1\n","counts = [label_counts[i] for i in range(num_classes)]\n","total = sum(counts)\n","\n","# Inverse frequency weighting\n","class_weights = [total / c for c in counts]\n","\n","print(\"Class weights:\", class_weights)\n","\n","# Convert to tensor (move to CUDA later)\n","class_weights = torch.tensor(class_weights)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cfJHSY6dSldm","executionInfo":{"status":"ok","timestamp":1764444784124,"user_tz":180,"elapsed":25,"user":{"displayName":"Marcelo Nóbrega","userId":"17870542757045971557"}},"outputId":"bbf2dc96-f18e-4b4b-f386-8783bf721841"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Class weights: [1.5601503759398496, 2.785234899328859]\n"]}]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from torch.nn import CrossEntropyLoss, MSELoss, BCEWithLogitsLoss\n","from transformers import DistilBertForSequenceClassification\n","from typing import Optional, Union\n","from transformers.modeling_outputs import SequenceClassifierOutput\n","\n","\n","class WeightedDistilBertForSequenceClassification(DistilBertForSequenceClassification):\n","    def __init__(self, config, class_weights=None):\n","        super().__init__(config)\n","\n","        # Store weights (tensor or None)\n","        if class_weights is not None:\n","            self.class_weights = torch.tensor(class_weights, dtype=torch.float)\n","        else:\n","            self.class_weights = None\n","\n","\n","    def forward(\n","        self,\n","        input_ids: Optional[torch.Tensor] = None,\n","        attention_mask: Optional[torch.Tensor] = None,\n","        head_mask: Optional[torch.Tensor] = None,\n","        inputs_embeds: Optional[torch.Tensor] = None,\n","        labels: Optional[torch.LongTensor] = None,\n","        output_attentions: Optional[bool] = None,\n","        output_hidden_states: Optional[bool] = None,\n","        return_dict: Optional[bool] = None,\n","    ) -> Union[SequenceClassifierOutput, tuple]:\n","\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        distilbert_output = self.distilbert(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        hidden_state = distilbert_output[0]              # (batch_size, seq_len, dim)\n","        pooled_output = hidden_state[:, 0]              # (batch_size, dim)\n","        pooled_output = self.pre_classifier(pooled_output)\n","        pooled_output = nn.ReLU()(pooled_output)\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.classifier(pooled_output)\n","\n","        loss = None\n","        if labels is not None:\n","\n","            # Detect problem type (same logic as original)\n","            if self.config.problem_type is None:\n","                if self.num_labels == 1:\n","                    self.config.problem_type = \"regression\"\n","                elif labels.dtype in (torch.long, torch.int):\n","                    self.config.problem_type = \"single_label_classification\"\n","                else:\n","                    self.config.problem_type = \"multi_label_classification\"\n","\n","            # Regression\n","            if self.config.problem_type == \"regression\":\n","                loss_fct = MSELoss()\n","                if self.num_labels == 1:\n","                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n","                else:\n","                    loss = loss_fct(logits, labels)\n","\n","            # Single-label classification (this is the one we modify)\n","            elif self.config.problem_type == \"single_label_classification\":\n","                if self.class_weights is not None:\n","                    # Move class weights to the same device\n","                    class_weights = self.class_weights.to(logits.device)\n","                    loss_fct = CrossEntropyLoss(weight=class_weights)\n","                else:\n","                    loss_fct = CrossEntropyLoss()\n","\n","                loss = loss_fct(\n","                    logits.view(-1, self.num_labels),\n","                    labels.view(-1)\n","                )\n","\n","            # Multi-label classification - unchanged\n","            elif self.config.problem_type == \"multi_label_classification\":\n","                loss_fct = BCEWithLogitsLoss()\n","                loss = loss_fct(logits, labels)\n","\n","        if not return_dict:\n","            output = (logits,) + distilbert_output[1:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return SequenceClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            hidden_states=distilbert_output.hidden_states,\n","            attentions=distilbert_output.attentions,\n","        )"],"metadata":{"id":"YaoZ8A-TG50Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from transformers import DistilBertForSequenceClassification\n","from transformers.modeling_outputs import SequenceClassifierOutput\n","\n","class WeightedDistilBert(DistilBertForSequenceClassification):\n","    def __init__(self, config, class_weights=None):\n","        super().__init__(config)\n","        self.class_weights = class_weights\n","\n","    def forward(self, *args, **kwargs):\n","        labels = kwargs.get(\"labels\", None)\n","\n","        # Remove labels so DistilBERT does NOT compute its own loss\n","        model_kwargs = {k: v for k, v in kwargs.items() if k != \"labels\"}\n","\n","        # Call the original DistilBERT forward\n","        outputs = super().forward(*args, **model_kwargs)\n","\n","        logits = outputs.logits\n","        loss = None\n","\n","        if labels is not None:\n","            labels = labels.to(logits.device)\n","            loss_fct = nn.CrossEntropyLoss(\n","                weight=self.class_weights.to(logits.device)\n","                if self.class_weights is not None\n","                else None\n","            )\n","            loss = loss_fct(logits, labels)\n","\n","        return SequenceClassifierOutput(\n","            loss = loss,\n","            logits = logits,\n","            hidden_states = outputs.hidden_states,\n","            attentions = outputs.attentions,\n","        )\n"],"metadata":{"id":"ozCTYXqMSv40"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iEmeQ7Xm3l_H"},"source":["Vamos criar as variáveis a partir do checkpoint do modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0yisyg9Rfyx3"},"outputs":[],"source":["from transformers import (\n","    AutoConfig,\n","    DistilBertConfig,\n","    DistilBertForSequenceClassification\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sPqQA3TT3l_I","executionInfo":{"status":"ok","timestamp":1764445210753,"user_tz":180,"elapsed":237,"user":{"displayName":"Marcelo Nóbrega","userId":"17870542757045971557"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"043ff31a-4a9f-4053-e6d0-0ed4dad876e9"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2752834623.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.class_weights = torch.tensor(class_weights, dtype=torch.float)\n","Some weights of WeightedDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["\n","\n","num_labels = len(set(lm_datasets[\"train\"][\"labels\"]))\n","\n","# config = DistilBertConfig.from_pretrained(model_checkpoint,\n","#                                     num_labels=num_labels,\n","#                                     class_weights=class_weights,\n","#                                     hidden_dropout_prob=0.1,\n","#                                     attention_probs_dropout_prob=0.1,\n","#                                     id2label={i: str(i) for i in range(num_labels)},\n","#                                     label2id={str(i): i for i in range(num_labels)}\n","#                                     )\n","#\n","model = WeightedDistilBertForSequenceClassification.from_pretrained(model_checkpoint,\n","    num_labels=num_labels,\n","    id2label={i: str(i) for i in range(num_labels)},\n","    label2id={str(i): i for i in range(num_labels)},\n","    class_weights=class_weights,   # ← vetor de pesos por classe\n","    # gamma=2.0\n","    )\n","\n","\n","# carregamento do checkpoint\n","# model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)"]},{"cell_type":"markdown","metadata":{"id":"VyPQTOF_3l_J"},"source":["Definindo hiperparâmetros do treinamento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jElf8LJ33l_K"},"outputs":[],"source":["from transformers import Trainer, TrainingArguments"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YbSwEhQ63l_L"},"outputs":[],"source":["training_args = TrainingArguments(\n","    resume_from_checkpoint=False,\n","    output_dir=\"./checkpoint/\",\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    save_total_limit=1,\n","    learning_rate=2e-5,\n","    num_train_epochs=4,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    # fp16=True,\n","    # optim=\"adam\",\n","    # gradient_accumulation_steps=1,\n","    load_best_model_at_end=True,\n","    report_to=\"none\",\n","    # ,\n","    # logging_dir=\"./logs/\",\n","    logging_steps=10,\n","    logging_strategy=\"steps\",\n","    # seed=42,\n","    remove_unused_columns=True,\n",")"]},{"cell_type":"markdown","metadata":{"id":"sZRbT9ui3l_N"},"source":["Classe de treino"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OEuqwIra3l_N"},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=lm_datasets[\"train\"],\n","    eval_dataset=lm_datasets[\"dev\"],\n","    data_collator=data_collator,\n","\n",")"]},{"cell_type":"code","source":["print(model.state_dict()['distilbert.transformer.layer.0.attention.q_lin.weight'][0][:5])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7QwjUEEyNPfy","executionInfo":{"status":"ok","timestamp":1764444432876,"user_tz":180,"elapsed":578,"user":{"displayName":"Marcelo Nóbrega","userId":"17870542757045971557"}},"outputId":"00778979-b157-48b1-9750-0f0993d170b7","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-0.0024,  0.0224, -0.0207,  0.0318, -0.0102], device='cuda:0')\n"]}]},{"cell_type":"markdown","metadata":{"id":"6Vvz34Td3l_O"},"source":["And we can train our model:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"collapsed":true,"id":"NyZvu_MF3l_P","outputId":"71de7ac1-96cc-4084-f725-6db8e3210f98","executionInfo":{"status":"ok","timestamp":1764445297716,"user_tz":180,"elapsed":71526,"user":{"displayName":"Marcelo Nóbrega","userId":"17870542757045971557"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='416' max='416' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [416/416 01:11, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.547800</td>\n","      <td>0.522398</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.319500</td>\n","      <td>0.486307</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.270100</td>\n","      <td>0.625172</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.042600</td>\n","      <td>0.666239</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["71.9787917137146\n"]}],"source":["import time\n","start = time.time()\n","trainer.train()\n","print (time.time() - start)"]},{"cell_type":"code","source":["print(model.state_dict()['distilbert.transformer.layer.0.attention.q_lin.weight'][0][:5])\n","\n","pred = trainer.predict(tokenized_datasets[\"test\"])\n","print(pred.predictions.shape)\n","print(pred.label_ids is not None)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"8OHcGDZkNUUw","executionInfo":{"status":"error","timestamp":1763663843284,"user_tz":180,"elapsed":572,"user":{"displayName":"Marcelo Campanelli","userId":"15387875644386929161"}},"outputId":"7ad33a9f-7df7-44ad-cdb3-b9719643002b","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-0.0025,  0.0222, -0.0210,  0.0312, -0.0100], device='cuda:0')\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"error","ename":"AttributeError","evalue":"'tuple' object has no attribute 'shape'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3738035304.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"]}]},{"cell_type":"markdown","metadata":{"id":"oMoeQwSDzsVY"},"source":["Analisando resultados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":180},"id":"nTk7CmMozq4D","outputId":"9c0f96c4-f44d-41d1-cb39-450b7848aa16","executionInfo":{"status":"ok","timestamp":1764445324345,"user_tz":180,"elapsed":379,"user":{"displayName":"Marcelo Nóbrega","userId":"17870542757045971557"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.85      0.78      0.81       215\n","           1       0.54      0.66      0.59        85\n","\n","    accuracy                           0.74       300\n","   macro avg       0.70      0.72      0.70       300\n","weighted avg       0.76      0.74      0.75       300\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","\n","pred = trainer.predict(tokenized_datasets[\"test\"])\n","\n","logits = pred.predictions[0] if isinstance(pred.predictions, tuple) else pred.predictions\n","\n","y_pred = logits.argmax(axis=-1)\n","\n","y_true = pred.label_ids\n","\n","print(classification_report(y_true, y_pred))\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"wWFGUuExcWHU","executionInfo":{"status":"ok","timestamp":1764445973907,"user_tz":180,"elapsed":19612,"user":{"displayName":"Marcelo Nóbrega","userId":"17870542757045971557"}},"outputId":"6413db6c-b51b-476e-9f42-dc6505a9b548"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","\n","save_path = \"/content/drive/MyDrive/Mestrado/Trabalho_LLM/Checkpoints_Distilbert\"\n","os.makedirs(save_path, exist_ok=True)\n"],"metadata":{"id":"eIcThGVFLQ2K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import shutil\n","import os\n","\n","src = \"/content/checkpoint/\"\n","dst = \"/content/drive/MyDrive/Mestrado/Trabalho_LLM/Checkpoints_Distilbert\"\n","\n","# create parent directory if needed\n","os.makedirs(os.path.dirname(dst), exist_ok=True)\n","\n","# copy the entire folder\n","shutil.copytree(src, dst, dirs_exist_ok=True)\n","\n","print(\"Checkpoint copied successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tj8iC5oULaNE","executionInfo":{"status":"ok","timestamp":1764446047826,"user_tz":180,"elapsed":9548,"user":{"displayName":"Marcelo Nóbrega","userId":"17870542757045971557"}},"outputId":"a0d854a6-2cee-4703-a5aa-98b032927871"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Checkpoint copied successfully!\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}